

.\redis-server.exe .\redis.windows-service.conf



# 1.redis生产环境启动方案

![image-20210425203616979](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210425203617.png)

![image-20210425203812659](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210425203812.png)





# 2.redis持久化对于生产环境中灾难恢复的意义



1.redis持久化 RDB,AOF区别，各自的特点是什么，适合什么场景

2.redis突然挂掉了，进程死了，或者所在的机器没了，反正遇到灾难性的故障，redis挂了。存放的数据全都没了，很惨，很重要的缓存数据，服务了很多重要的系统和服务。redis会重启，重启之后，需要费很大的劲去恢复redis。redis如果单单存放在内存中，是没有任何办法应对一些灾难性的故障的。





# 3.分析Redis的RDB和AOF两种持久化机制的工作原理

持久化主要是为了灾难恢复，数据恢复，也可以归类到高可用的一个环节中

## RDB

对redis中的数据执行周期性的持久化(每隔一段时间生成redis内存中的数据的一份完整快照)，





## AOF

**AOF文件是存放每条写命令的**

操作系统会有一个os cache，写文件不会直接写入磁盘，会先往os cache中写入，然后到一定时间在从os cache到disf file

AOF是每隔一段时间调用一次操作系统的fsync操作，强制将os cache中的数据刷入磁盘文件中。

redis中的数据是有一定限量的，不可能无限增长，导致AOF文件无限增长。到一定时候redis就会用缓存淘汰算法比如说LRU，删除一些数据

到AOF文件大到一定时候，AOF就会做rewrite(不是基于已存在的AOF文件，而是当时redis的状态)操作，会基于redis内存中的数据，来重新构造一个更小的AOF文件





## 对比

如果同时使用RDB和AOF两种持久化数据，在redis重启的时候或优先使用AOF文件来重构数据，因为数据更加完整



**RDB优点**

1. RDB会生成多个数据文件，每个数据文件都代表了某一时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件，发送到一些远程的安全存储服务上去。
2. 对redis对外提供的读写服务，影响非常下，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘io操作来进行rdb持久化即可
3. 相对AOF持久化来说，直接基于RDB来重启和回复redis更快



**RDB缺点**

1. RDB生成数据快照一般是5分钟，或者更长，这个时候宕机，那么就丢失了5分钟的数据
2. 如果RDB在fork子进程来执行RDB的时候，如果文件特别大，可能会导致服务暂停数毫秒，甚至数秒。所以RDB间隔不能特别大



**AOF优点**

1. aof更好的保护数据不丢失，一般aof会每隔1秒进行一次fsync操作，最多丢失1秒的数据
2. 使用append-only写入，不会有磁盘寻址的开销，写入性能高，不容易被破坏
3. rewrite是对新老文件一起写入，然后进行merge
4. aof是以记录命令的方式进行的，可以查看所有的操作记录，防止flushall的破坏操作





**AOF缺点**

1. AOF文件更大
2. 性能有降低
3. AOF可能有bug，不能恢复出一模一样的数据
4. 数据恢复的时候比较慢，不方便，可能需要自己写脚本



![image-20210426210731824](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210426210739.png)





# 4.redis的RDB持久化配置以及数据恢复实验

配置RDB持久化操作：

~~~bash
save 60 1000
~~~

可以设置多个

每隔60s,如果有超过1000个key发生了变化，就新生成一个dump.rdb文件，就是当前redis内存中的完整数据的快照(snapshotting)，也可以手动调用save 或者 bgsave，同步或异步执行rdb快照生成。



## 关闭测试：

~~~
shutdown
~~~

使用之后，会在关闭直接保存redis数据

~~~~
异常关闭，比如kill -9
~~~~

使用之后，不会保存数据





# 5.深入讲解redis的AOF持久化的各种操作和相关实验

AOF默认是关闭的

~~~bash
appendonly yes
~~~

打开aof持久化机制，在生产环境中一般来说AOF是要打开的，除非说随便丢个几分钟数据都无所谓。

打开AOF之后，redis每次接受到一条命令后，就会写入日志文件中，当然先写入os cache中，然后每隔一段时间 fsync中，如果AOF和RDB都开启了，优先通过AOF文件恢复数据。

**fsync策略有3种**

~~~
always:每次写入一条数据，立即执行fsync
	mysql：内存策略，大量磁盘，qps一般 1 - 2K
	redis：内存，磁盘持久化 qps 单机 一般 1w+ 没问题
everysec:每秒将os cache中的数据fsync到磁盘，一般都这么配置
no:redis仅仅将数据写入os chache就不管了，靠os自己的策略掉用fsync
~~~



## 测试

![image-20210427214935191](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210427214958.png)

![image-20210427214940080](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210427215002.png)

可以看到在appendonly.aof文件中，可以看到刚刚的命令日志，他们其实就是先写入到os cache的，然后1秒后调用fsync写入到aof文件中.

kill _ 9后，数据也恢复了

![image-20210427215236004](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210427215236.png)_



## rewrite

redis中的数据可能是优先的，很多数据可能会自动过期，可能会被用户删除，可能会被redis用缓存清除的算法清理掉。

redis中的数据会不断的淘汰，只有一些常用的数据会被自动保留在redis内存中。

所以一些已经被淘汰的数据会存在于aof文件中，aof文件就一个，会不断的变大，很大。

所以aof会自动在后台每隔一段时间进行rewrite操作，比如日志里面已经存放了100w数据的写日志；redis内存只剩10w数据，基于内存中当前10w数据构建一套最新的日志，覆盖老的aof文件，确保aof文件不会过大，保持跟redis内存数据量一致。

redis2.4之前，还需要手动调用 BGREWRITEAOF 命令执行aof rewrite



**rewrite相关配置**

redis会记录上次rewrite文件的大小，如果超过上次aof文件percentage的百分比大小就进行rewrite

min-size：最小这么大才进行rewrite

~~~bash
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
~~~

比如上次是128mb，如果现在是256mb，就会触发rewrite，但是还要确认min-size。



**rewrite步骤**

~~~
1.redis fork一个子进程
2.子进程基于当前redis内存中的数据，构建一个新的aof文件
3.redis主线程，在收到客户端的写操作之后，在内存中写入操作记录，并写入旧的aof文件
4.子进程写完新数据后，redis主进程也会将内存中的新的日志追加到新的aof文件中
5.用新的aof文件替换旧的
~~~



## aof和rdb同时工作

~~~
如果rdb在执行snapshotting操作，那么redis不会执行aof的rewrite操作。
如果在执行aof rewrite操作， 那么就不会执行rdb snapshotting。
如果在执行rdb snapshotting，用户调用了BGREWRITEAOF命令，那么等rdb操作完了之后就会执行aof操作
如果同时有aof文件和rdb文件，那么redis重启的时候会使用aof文件进行数据恢复
~~~

如果aof有部分数据，rdb也有部分数据。但是redis重启的时候，不会加载rdb中的数据





# 6.在项目中部署redis企业级数据备份方案以及各种踩坑的数据恢复容灾演练

RDB的生成策略，用默认的也差不多。根据实际情况修改

~~~bash
save 60 10000
~~~

AOF一定要打开，fsync：everysec

~~~bash
auto-aof-rewrite-percentage 100 就是当前文件膨胀当超过上次的100%
auto-aof-rewrite-min-size 64mb  根据数据量来定
~~~





## 备份方案

~~~
1.写crontab定时调度脚本做数据备份
2.每小时都copy一份rdb备份，到一个目录中，只保存最近48小时的备份
3.每天都保留一份当日的rdb备份，到一个目录，只保存最近一个月的
4.每次copy的时候，把太旧的备份删除
5.当天晚上前将服务器的所有数据备份，发送一份到远程的云服务上
~~~





### 每小时备份

![image-20210428211719914](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210428211720.png)cp

### 每天备份

![image-20210428211528175](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210428211528.png)







## 数据恢复方案

![image-20210428214422758](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210428214422.png)

![image-20210428215201292](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210428215201.png)





![image-20210428215458857](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210428215458.png)







# 7.redis如何通过读写分离来承载读请求QPS超过10万+？

redis支持高并发的瓶颈：

~~~
单机redis：大概qps大概在上万~几万不等(根据业务操作的复杂性，lua脚本)
~~~



如果要支持超过10万+的并发，应该怎么做？

~~~
读写分离：一般来说，对于缓存，一般来说都是支撑读高并发，写的请求是较少的，可能一秒也就几千
redis 主从
水平扩容，如果qps在增加，就继续增加redis slave节点
~~~



![image-20210429205523987](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210429205531.png)





# 8.redis主从架构(redis replication)

redis主从架构->读写分离架构->可支持水平扩展的读高并发架构

~~~
master 节点：接收写请求
solve  节点：接收读请求
~~~



1、redis采用异步的方式复制数据到slave节点，slave会周期的确认自己每次复制的数据量

2、一个master节点可以有多个slave节点

3、slave节点可以连接其他的slave节点

4、slave节点复制的时候，不会block master节点的工作

5、slave节点复制的时候也不会block自己的查询操作，他会用旧的数据提供服务，复制完成后，删除旧的数据及，然后加载新的数据，这个时候会暂停

6、slave节点主要用来做进行横向扩容，读写分离，扩容的slave节点可以提高读的吞吐量。



![image-20210429210243881](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210429210243.png)

如果使用了主从架构，那么**master节点必须开启持久化**





# 9.redis主从复制原理、断点续传、无磁盘化复制、过期key处理

## 1.主从复制原理

1.当启动一个slave节点的时候他会发送==PSYNC==命令给master节点

- 如果是slave掉线后重新连接master，那么master只会复制给slave部分数据；**部分数据**

- 如果是第一次连接，那么会触发==full resynchronization==  **全量数据**

2.开始==full resynchronization==的时候，master会启动一个后台进程，开始生成一份rdb快照文件，同时会将从客户端收到的所有写命令缓存在内存中。rdb文件生成完毕后，master会将这个rdb文件发送给slave，salve会将收到的文件写入磁盘，然后在加载到内存中，然后master会将缓存的命令发送给salve，salve同步数据

3.salve如果跟master有网络故障，断开了连接，会自动重连，如果有多个salve都来重新连接，只会生成一份rdb文件，发送给所有的salve





## 2.断点续传

如果网络连接断掉了，可以接着从上一次复制停下来的地方，继续复制。

master中存在一个==backlog==，master和salve都会保存一个==replica offset==和==master id==，offset保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制。如果没有找到对应的offset，会执行==full resynchronization==





## 3.无磁盘化复制

master在内存中直接创建rdb，然后发送给slave，不会在本地磁盘创建。

~~~bash
repl-diskless-sync
repl-diskless-sync-delay # 等待一定时间开始复制
~~~





## 4.过期key处理

salve不会过期key，只会等待master过期key，如果master过期了一个key，或者通过了淘汰算法了一个key，那么就会模拟一个del命令发送给slave





# 10.深入剖析redis replication原理和完整运行流程



## 1.复制的完整流程

1.slave启动，保存了master节点的信息(host 和ip，从redis.conf中读取)，但是没有开始复制

2.slave节点内有一个定时任务，每秒检查是否有新的master节点要连接和复制，如果发现，就跟master建立socket连接

3.salve节点发送ping命令给master

4.口令认证，如果master设置了requirepass，那么slave必须发送master auth 进行认证

5.master第一次是全量复制，将所有数据发送个slave

6.master后续将写操作，同步复制给slave





![image-20210501135405692](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210501135508.png)





## 2.数据同步相关的核心机制

第一次slave连接master的时候是全量复制

~~~
1.master和slave都会维护一个offset
	master和slave都builder不断累加offset
	slave每秒都会上报自己的slave，同时master也会记录各个slave的offset
~~~


~~~
2.backlog
	master节点有一个backlog，默认是1mb大小
	master节点给slave节点复制数据的时候，也会将数据在bcklog中同步一份
backlog主要用来做全量复制后的 中断 的 增量复制
~~~


~~~
3.master run id
	info server，可以看到master run id
	如果根据host + ip定位master，是不靠谱的，如果master重启或者数据发生了变化，那么slave应该根据不同的run id区分，run id 不同就做全量复制
	如果需要不更改run id重启redis，可以使用redis-cli debug reload命令
~~~

~~~
4.psync
	slave节点使用psync从master 进行复制， psync runid offset
	master节点会根据自身情况返回响应信息，可能是FULLRESYNC runid offset触发全量复制，可能是CONTINUE触发增量复制
~~~





## 3.全量复制

1. master执行**bgsave**，在本地生成一分rdb快照文件
2. master将rdb快照文件发送给slave，如果rdb复制时间超过**60s(repl-timeout)**,那么slave就会认为复制失败，可以适当调解这参数
3. 比如说传输一个6g的文件，每秒100mb，就很可能会超过60s
4. master在生成rdb的时候，会将所有新的写命令缓存在内存中，在slave保存完毕rdb文件后，在将新的写命令发送给slave
5. **client-output-buffer-limit slave 256mb 64mb 60**，如果在复制期间，内存缓存区持续消耗超过64mb，或者一次性超过256mb，那么停止复制，复制失败。
6. salve收到rdb文件后，会清空自己的数据，然后保存到磁盘，然后在加载，此时基于旧数据提供服务
7. 如果slave开启了aof，那么会立即执行BGREWRITEAOF，重写aof



## 4.增量复制

1. 如果全量复制过程中，master-slave网络连接断掉，那么slave重新连接master时，会触发增量复制
2. master直接从自己的**backlog**中获取部分丢失的数据，发送给salve，默认backlog是1mb
3. master就是根据slave发送的**psync**中的offset从backlog获取数据的

 



![image-20210501162620481](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210501162625.png)





# 11.在项目中部署redis的读写分离架构（包含节点间认证口令）

gcc安装

~~~bash
yum install gcc -y
sudo yum install -y centos-release-scl
sudo yum install -y devtoolset-8-gcc*


source /opt/rh/devtoolset-8/enable

或者

mv /usr/bin/gcc /usr/bin/gcc-4.8.5

ln -s /opt/rh/devtoolset-8/root/bin/gcc /usr/bin/gcc

mv /usr/bin/g++ /usr/bin/g++-4.8.5

ln -s /opt/rh/devtoolset-8/root/bin/g++ /usr/bin/g++

gcc --version
~~~







## 安装redis slave

~~~bash
wget http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz
tar -zxvf tcl8.6.1-src.tar.gz
cd tcl8.6.1/unix/
./configure
make && make install
~~~



~~~bash
wget http://download.redis.io/releases/redis-6.0.6.tar.gz
tar -zxvf redis-6.0.6.tar.gz
cd redis-6.0.6
make && make instal
~~~

1. redis utils目录中，有个**redis_init_scrpi**t脚本
2. 将**redis_init_scrpit**脚本拷贝到/etc/init.d中，将**redis_init_scrpi**t重命名为**redis_6379**,6379代表监听的端口号

~~~bash
cd utils/
cp redis_init_script /etc/init.d/redis_6379
~~~

3. 修改**redis_6379**中的第6行==REDISPORT==，设置为相同的端口号(默认为6379)

4. 创建两个目录:/etc/redis（存放redis的配置文件）,/var/redis/6379（存放redis的持久化文件）

~~~bash
mkdir /etc/redis && mkdir -p /var/redis/6379
~~~

5. 修改redis配置文件(默认在根目录下，redis.conf)，拷贝到/etc/redis目录中，修改名字为6379.conf。

~~~bash
cp ../redis.conf /etc/redis/6379.conf
~~~

6. 修改redis.conf中的配置文件为生产环境

~~~bash
vim /etc/redis/6379.conf

bind 0.0.0.0
daemonize yes										# 以守护进程运行
pidfile   /var/run/redis_6379.pid					# redis的pid文件位置
port 6379											# 设置redis监听的端口号
dir /var/redis/6379/								# 设置持久化文件保存的位置
~~~

7. 启动redis,执行

~~~bash
cd /etc/init.d
chmod 777 redis_6379 
./redis_6379 start
~~~

8. 确认redis进程是否启动， ps -ef |grep redis
9. redis随系统启动

~~~bash
chkconfig redis_6379
~~~



![image-20210501171132040](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210501171852.png)

在slave节点中配置

~~~bash
slaveof 192.168.1.1 6379

replicaof 192.168.1.107 6379
~~~

开启强制读写分离

~~~
slave-read-only yes
~~~



## 安装认证

slave

~~~
masterauth like
~~~

master

~~~
requirepass like
~~~



开放端口，如果没有

![image-20210501173404356](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210501173407.png)

~~~bash
systemctl disable firewalld
~~~





## 启动

~~~
/etc/init.d/redis_6379 start && redis-cli
~~~

![image-20210502121748044](https://gitee.com/likeloveC/picture_bed/raw/master/img/8.26/20210502122335.png)